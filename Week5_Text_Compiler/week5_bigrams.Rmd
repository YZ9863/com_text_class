---
title: "Week 4 Bigrams Homework"
author: "Rob Wells"
date: '2025-02-20'
output: html_document
---

# Jour 689 Spring 2025:


```{r}
#load tidyverse, tidytext, rio, janitor libraries

library(tidyverse)
library(tidytext)
library(janitor)
library(rio)
library(dplyr)

```

I first rename the file as project.

```{r}

project <- articles_df
rm(articles_df)
```


# Tokenize the sentence column
Copy the code from the in-class bigrams exercise and tokenize just the sentence column from your dataframe

Hint: you're changing just one variable

```{r}
sentence <- str_replace_all(project$sentence, "- ", "")
sentence_tk <- tibble(sentence,)

sentence_tokenized <- sentence_tk %>%
  unnest_tokens(word,sentence)

sentence_tokenized
```

#Remove stopwords and count the words
```{r}
stopwords <- stop_words
stopwords

stopwords |> 
  count(lexicon)

```


```{r}

data(stop_words)

sentence_tokenized <- sentence_tokenized %>%
  anti_join(stop_words, by = c("word" = "word")) %>%
  filter(word != "temp_file") %>%
  filter(word != "stories_corpus") %>%
  filter(!grepl('[0-9]', word))

# Word Count

sentence_word_ct <- sentence_tokenized %>%
  count(word, sort=TRUE)

sentence_word_ct

write_csv(sentence_word_ct, "sentence_word_ct.csv")
```


# Create Bigrams

```{r}
bigrams <- sentence_tk %>%
  unnest_tokens(bigram, sentence, token="ngrams", n=2)

bigrams

#Filter out stop words.

bigrams1 <- bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams2 <- bigrams1 %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) |>
  filter(!is.na(word1)) |>
  filter(!is.na(word2)) 

bigram3 <- bigrams2 %>%
  count(word1, word2, sort = TRUE)

bigram3
#write_csv(stories_bigram_cts_post1940, "../output/post1940_lynch_bigram_count.csv")

```


# Write 250 words about what your learned analyzing the list of tokens and bigrams. Include questions about the process and any difficulties you encountered.
